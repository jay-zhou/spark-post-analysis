#####Here is the test of 8363 files, subset of one million files. 

* The total 8363 files are under data/load/ directory and the size is 36M.
```
hduser@ubuntu:~/spark-code/analyse-posts/data$ du -sh load/
36M	load/
hduser@ubuntu:~/spark-code/analyse-posts/data$ ls load/* | wc -l
8363
```
![](https://cloud.githubusercontent.com/assets/13358534/8842331/bc6ff7a8-30c6-11e5-9ed9-ecf6dbc60aa4.png)

* Run ProcessPosts to load the data to Cassandra tables:

`time /usr/local/spark/bin/spark-submit --class stkof.ProcessPosts --master local[4] target/scala-2.10/ProcessPosts-assembly-0.1-SNAPSHOT.jar`

![](https://cloud.githubusercontent.com/assets/13358534/8842423/14562f7c-30c8-11e5-8f00-a0a85c90e7ea.png)

* Check the Cassandra tables

In the 8363 files, there is only one file that contains "Apache Storm" terms. 
![](https://cloud.githubusercontent.com/assets/13358534/8842570/d04d1c6c-30c9-11e5-8d26-1aa9e68cc290.png)

Go to data/load directory to check and the result is correct. Only the file: 24750917.xml contains "Apache Storm" terms.
![](https://cloud.githubusercontent.com/assets/13358534/8842664/039af2d2-30cb-11e5-8697-61457998dc19.png)

* Before going the next step, let's mock up some data for other months by inserting some data into sof_posts_data.monthly_aggregate_astorm_post table. 
```
cqlsh> insert into sof_posts_data.monthly_aggregate_astorm_post(create_year, create_month, post_count) values ('2014', '08', 3);
cqlsh> insert into sof_posts_data.monthly_aggregate_astorm_post(create_year, create_month, post_count) values ('2014', '09', 17);
cqlsh> insert into sof_posts_data.monthly_aggregate_astorm_post(create_year, create_month, post_count) values ('2014', '10', 12);
cqlsh> insert into sof_posts_data.monthly_aggregate_astorm_post(create_year, create_month, post_count) values ('2014', '11', 17);
cqlsh> select * from sof_posts_data.monthly_aggregate_astorm_post;
```
![](https://cloud.githubusercontent.com/assets/13358534/8842749/1c3fa0a2-30cc-11e5-8d80-02bc362599d5.png)

* Run ExtractPosts to get the results

`time /usr/local/spark/bin/spark-submit --class stkof.ExtractPosts --master local[4] target/scala-2.10/ProcessPosts-assembly-0.1-SNAPSHOT.jar`
![](https://cloud.githubusercontent.com/assets/13358534/8842813/295f7b4e-30cd-11e5-858e-d218654d2104.png)

Check the result in **post_analysis.txt** which is generated by ExtractPost application.
![](https://cloud.githubusercontent.com/assets/13358534/8842852/c090b712-30cd-11e5-861b-7b66eb12c147.png)

* Run the PlotPosts to generate the graph.

` time /usr/local/spark/bin/spark-submit --class stkof.PlotPosts --master local[4] target/scala-2.10/ProcessPosts-assembly-0.1-SNAPSHOT.jar`
![](https://cloud.githubusercontent.com/assets/13358534/8842987/847119c8-30cf-11e5-8604-0e43a906fe1a.png)


![](https://cloud.githubusercontent.com/assets/13358534/8842960/1b47035e-30cf-11e5-9955-dcabedb9d7f5.png)
